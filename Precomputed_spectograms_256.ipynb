{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN6d0yFiOwzaWdaFxLQNBQ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6a6ed9d2d1d4bf4944cb43d2ed3907d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89fe9805f4cd46beb7d043536d61c03e",
              "IPY_MODEL_0bb6e9ba95474dfdbf925750be43242c"
            ],
            "layout": "IPY_MODEL_854cd55721f749d79d864349fa9b269c"
          }
        },
        "89fe9805f4cd46beb7d043536d61c03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8782a86e9b9541ceb6ffc0bf5a9de88d",
            "placeholder": "​",
            "style": "IPY_MODEL_4a843cfaa42e4fa7b662230ab9458b62",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "0bb6e9ba95474dfdbf925750be43242c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac099204eaa8473ba2eb9759f6d748d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e6ce07183aa4d548551fdb1b5ea790c",
            "value": 1
          }
        },
        "854cd55721f749d79d864349fa9b269c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8782a86e9b9541ceb6ffc0bf5a9de88d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a843cfaa42e4fa7b662230ab9458b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac099204eaa8473ba2eb9759f6d748d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6ce07183aa4d548551fdb1b5ea790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "856579a7a209474e9b9f26e25b21e1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a144fa2bef02472b91287c52c021f0a2",
              "IPY_MODEL_333da846c01b49ac89226cebf72fb218"
            ],
            "layout": "IPY_MODEL_e82f8403d40e4103acd8f06e2b77e532"
          }
        },
        "a144fa2bef02472b91287c52c021f0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6ee70a9da04cad9020e0db4ce5ed94",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8b47b43f1d43269f141365eb50c5ff",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "333da846c01b49ac89226cebf72fb218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f880959c02cb4d24976781232c9ea44d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d26434fd89d846928110896d1c607ef6",
            "value": 1
          }
        },
        "e82f8403d40e4103acd8f06e2b77e532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6ee70a9da04cad9020e0db4ce5ed94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8b47b43f1d43269f141365eb50c5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f880959c02cb4d24976781232c9ea44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26434fd89d846928110896d1c607ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/2024-final-filip-martin/blob/main/Precomputed_spectograms_256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "input_folder = \"./chunks\"  # Folder with HDF5 chunks\n",
        "combined_output_file = \"combined_spectrograms.h5\"\n",
        "\n",
        "# Initialize empty lists for spectrograms and labels\n",
        "all_spectrograms = []\n",
        "all_labels = []\n",
        "class_mapping = None  # Placeholder for class mapping\n",
        "\n",
        "# Read all HDF5 chunk files\n",
        "for file in os.listdir(input_folder):\n",
        "    if file.endswith(\".h5\"):\n",
        "        chunk_file = os.path.join(input_folder, file)\n",
        "        with h5py.File(chunk_file, \"r\") as hf:\n",
        "            spectrograms = np.array(hf[\"spectrograms\"])\n",
        "            labels = np.array(hf[\"labels\"])\n",
        "            all_spectrograms.append(spectrograms)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "            # Retrieve class_mapping from the first file\n",
        "            if class_mapping is None and \"class_mapping\" in hf.attrs:\n",
        "                class_mapping = hf.attrs[\"class_mapping\"]\n",
        "\n",
        "        print(f\"Loaded {len(spectrograms)} samples from {file}\")\n",
        "\n",
        "# Concatenate all data\n",
        "all_spectrograms = np.concatenate(all_spectrograms, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "# Save combined data to a single HDF5 file, including class_mapping\n",
        "with h5py.File(combined_output_file, \"w\") as hf:\n",
        "    hf.create_dataset(\"spectrograms\", data=all_spectrograms, compression=\"gzip\")\n",
        "    hf.create_dataset(\"labels\", data=all_labels, compression=\"gzip\")\n",
        "    if class_mapping:\n",
        "        hf.attrs[\"class_mapping\"] = class_mapping  # Add class mapping attribute\n",
        "    hf.attrs[\"description\"] = \"Combined spectrogram dataset\"\n",
        "\n",
        "print(f\"Combined dataset saved to: {combined_output_file}\")\n",
        "print(f\"Total samples: {all_spectrograms.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVaEUGGjF_8P",
        "outputId": "0c579133-5953-4336-fa2c-2a4dfa4a458c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3000 samples from chunk_1.h5\n",
            "Loaded 3000 samples from chunk_0.h5\n",
            "Loaded 3000 samples from chunk_2.h5\n",
            "Loaded 3000 samples from chunk_3.h5\n",
            "Combined dataset saved to: combined_spectrograms.h5\n",
            "Total samples: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Path to your HDF5 file\n",
        "file_path = \"/content/combined_spectrograms.h5\"\n",
        "\n",
        "# Function to list datasets and attributes\n",
        "def inspect_hdf5_file(file_path):\n",
        "    \"\"\"List all datasets and attributes in an HDF5 file.\"\"\"\n",
        "    with h5py.File(file_path, \"r\") as hf:\n",
        "        print(\"\\n--- HDF5 File Structure ---\")\n",
        "        def print_hierarchy(name, obj):\n",
        "            if isinstance(obj, h5py.Dataset):\n",
        "                print(f\"Dataset: {name} | Shape: {obj.shape} | Dtype: {obj.dtype}\")\n",
        "            elif isinstance(obj, h5py.Group):\n",
        "                print(f\"Group: {name}\")\n",
        "\n",
        "        # Print all groups and datasets\n",
        "        hf.visititems(print_hierarchy)\n",
        "\n",
        "        # Print attributes\n",
        "        print(\"\\n--- File Attributes ---\")\n",
        "        for attr in hf.attrs:\n",
        "            print(f\"{attr}: {hf.attrs[attr]}\")\n",
        "\n",
        "# Inspect the file\n",
        "inspect_hdf5_file(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dw-QUOA9Ytt",
        "outputId": "8e897090-a9e2-4c6d-89c6-1861c5ed47a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- HDF5 File Structure ---\n",
            "Dataset: labels | Shape: (12000,) | Dtype: int32\n",
            "Dataset: spectrograms | Shape: (12000, 256, 256) | Dtype: float32\n",
            "\n",
            "--- File Attributes ---\n",
            "class_mapping: {'engine': 0, 'speech': 1, 'music': 2}\n",
            "description: Combined spectrogram dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Step 1: Define a Custom Data Generator for HDF5 ---\n",
        "class HDF5DataGenerator(Sequence):\n",
        "    def __init__(self, h5_file, batch_size, num_classes, input_size=(128, 128), train=True, split=0.8):\n",
        "        self.h5_file = h5_file\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Open HDF5 file and load indices\n",
        "        with h5py.File(self.h5_file, \"r\") as hf:\n",
        "            self.spectrograms = hf[\"spectrograms\"]\n",
        "            self.labels = hf[\"labels\"]\n",
        "            total_samples = len(self.labels)\n",
        "\n",
        "        # Split into train and validation\n",
        "        split_index = int(total_samples * split)\n",
        "        if train:\n",
        "            self.indices = np.arange(0, split_index)\n",
        "        else:\n",
        "            self.indices = np.arange(split_index, total_samples)\n",
        "\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X = np.zeros((len(batch_indices), *self.input_size, 1), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_indices), self.num_classes), dtype=np.float32)\n",
        "\n",
        "        with h5py.File(self.h5_file, \"r\") as hf:\n",
        "            for i, idx in enumerate(batch_indices):\n",
        "                X[i, :, :, 0] = hf[\"spectrograms\"][idx]  # Load spectrogram\n",
        "                label = hf[\"labels\"][idx]  # Load label\n",
        "                y[i, label] = 1.0  # One-hot encode label\n",
        "        return X, y\n",
        "\n",
        "# --- Step 2: Paths and Generator Initialization ---\n",
        "h5_file = \"./chunks/chunk_0.h5\"  # Your HDF5 file containing preprocessed data\n",
        "batch_size = 16\n",
        "input_size = (256, 256)\n",
        "num_classes = 3  # engine, speech, music\n",
        "\n",
        "train_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=True)\n",
        "val_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=False)\n",
        "\n",
        "# --- Step 3: Build the CNN Model ---\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(*input_size, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 4\n",
        "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten and Dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),  # Dropout for regularization\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# --- Step 4: Train the Model ---\n",
        "epochs = 10\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=epochs)\n",
        "\n",
        "# --- Step 5: Plot Training History ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Optional: Save the Model ---\n",
        "model.save(\"cnn_classifier_from_hdf5.h5\")\n",
        "print(\"Model saved as 'cnn_classifier_from_hdf5.h5'\")"
      ],
      "metadata": {
        "id": "5vHJzXzXxSqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11c6bf60-131b-4609-bb28-3058de72baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │      \u001b[38;5;34m12,845,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m771\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,022,627\u001b[0m (53.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,022,627</span> (53.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,020,195\u001b[0m (53.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,020,195</span> (53.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 2s/step - accuracy: 0.4486 - loss: 1.6379 - val_accuracy: 0.0000e+00 - val_loss: 2.3937\n",
            "Epoch 2/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.5506 - loss: 1.1312 - val_accuracy: 0.0000e+00 - val_loss: 3.8902\n",
            "Epoch 3/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 2s/step - accuracy: 0.5975 - loss: 1.0295 - val_accuracy: 0.0000e+00 - val_loss: 6.8214\n",
            "Epoch 4/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 2s/step - accuracy: 0.6103 - loss: 0.9725 - val_accuracy: 0.0050 - val_loss: 7.9629\n",
            "Epoch 5/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.6195 - loss: 0.9198 - val_accuracy: 0.0400 - val_loss: 13.4196\n",
            "Epoch 6/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.6727 - loss: 0.8428 - val_accuracy: 0.0833 - val_loss: 18.2040\n",
            "Epoch 7/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.6340 - loss: 0.8972 - val_accuracy: 0.0717 - val_loss: 28.1944\n",
            "Epoch 8/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.7058 - loss: 0.7765 - val_accuracy: 0.0833 - val_loss: 13.2857\n",
            "Epoch 9/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 2s/step - accuracy: 0.7425 - loss: 0.6861 - val_accuracy: 0.1333 - val_loss: 8.4216\n",
            "Epoch 10/10\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.7661 - loss: 0.5765 - val_accuracy: 0.1000 - val_loss: 1.7417\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'cnn_classifier_from_hdf5.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimalizace předchozí sítě\n",
        "\n",
        "## Optimalizace pro běh na GPU\n",
        "- přidán JIT a mixed_float16\n",
        "- h5 file nahrán do paměti\n",
        "\n",
        "## Optimalizace učení\n",
        "- Přidán clipnorm pro zabránění exploding gradientu\n",
        "- Snížen learning rate na 0.0001\n"
      ],
      "metadata": {
        "id": "Acohm5ePDC-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Enable Mixed Precision and XLA Compilation ---\n",
        "mixed_precision.set_global_policy('mixed_float16')  # Use float16 for faster computation\n",
        "tf.config.optimizer.set_jit(True)  # Enable JIT compilation for TensorFlow graphs\n",
        "\n",
        "# --- Step 1: Load HDF5 Data into Memory ---\n",
        "def load_h5_to_memory(h5_file, split=0.8):\n",
        "    \"\"\"\n",
        "    Load HDF5 datasets into memory and split into train and validation sets.\n",
        "    \"\"\"\n",
        "    with h5py.File(h5_file, \"r\") as hf:\n",
        "        spectrograms = np.array(hf[\"spectrograms\"], dtype=np.float32) / 255.0  # Normalize\n",
        "        labels = np.array(hf[\"labels\"], dtype=np.int32)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    num_classes = len(np.unique(labels))\n",
        "    labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "    # Split into train and validation sets\n",
        "    split_index = int(len(labels) * split)\n",
        "    X_train, X_val = spectrograms[:split_index], spectrograms[split_index:]\n",
        "    y_train, y_val = labels[:split_index], labels[split_index:]\n",
        "\n",
        "    # Add channel dimension for Conv2D input\n",
        "    X_train = X_train[..., np.newaxis]  # Shape: (samples, 256, 256, 1)\n",
        "    X_val = X_val[..., np.newaxis]\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val)\n",
        "\n",
        "# Path to HDF5 file\n",
        "h5_file = \"./chunks/chunk_0.h5\"\n",
        "(X_train, y_train), (X_val, y_val) = load_h5_to_memory(h5_file)\n",
        "\n",
        "print(f\"Training Data Shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation Data Shape: {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "# --- Step 2: Define In-Memory Data Generator ---\n",
        "class InMemoryDataGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(len(self.X))\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X_batch = self.X[batch_indices]\n",
        "        y_batch = self.y[batch_indices]\n",
        "        return X_batch, y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "# Initialize Data Generators\n",
        "batch_size = 16\n",
        "train_generator = InMemoryDataGenerator(X_train, y_train, batch_size)\n",
        "val_generator = InMemoryDataGenerator(X_val, y_val, batch_size)\n",
        "\n",
        "# --- Step 3: Build the CNN Model ---\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal',\n",
        "                  input_shape=(256, 256, 1)),  # Explicit input shape\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 4\n",
        "    layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten and Dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.01),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # num_classes = 3\n",
        "])\n",
        "\n",
        "# Compile the model with gradient clipping\n",
        "optimizer = Adam(learning_rate=1e-4, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- Step 4: Define Callbacks ---\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# --- Step 5: Train the Model ---\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[]\n",
        ")\n",
        "\n",
        "# --- Step 6: Plot Training History ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Step 7: Save the Model ---\n",
        "model.save(\"optimized_cnn_model_in_memory.h5\")\n",
        "print(\"Model saved as 'optimized_cnn_model_in_memory.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hnQFScQLDCcJ",
        "outputId": "c024e864-56c2-4628-88b0-c8e7c0418e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Shape: (2400, 256, 256, 1), (2400, 3)\n",
            "Validation Data Shape: (600, 256, 256, 1), (600, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_45               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_18 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_46               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_19 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_42 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_47               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_20 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_43 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_48               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_21 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_49               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_22 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_50               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_23 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_51               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_24 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_52               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_25 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │      \u001b[38;5;34m16,777,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_53               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_26 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m771\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_45               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_46               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_47               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_48               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_49               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_50               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_51               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_52               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_53               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,954,787\u001b[0m (68.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,954,787</span> (68.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,952,355\u001b[0m (68.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,952,355</span> (68.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,432\u001b[0m (9.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> (9.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.3758 - loss: 1.4037 - val_accuracy: 0.0000e+00 - val_loss: 12.4459\n",
            "Epoch 2/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4419 - loss: 1.1893 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 3/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4767 - loss: 1.0787 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 4/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4977 - loss: 0.9993 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 5/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5040 - loss: 0.9919 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 6/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5429 - loss: 0.9591 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 7/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5469 - loss: 0.9144 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 8/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5365 - loss: 0.8953 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 9/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5598 - loss: 0.8711 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 10/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5842 - loss: 0.8756 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 11/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5721 - loss: 0.8573 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 12/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6033 - loss: 0.8167 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 13/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5940 - loss: 0.8602 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 14/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6144 - loss: 0.7871 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 15/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6088 - loss: 0.7917 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 16/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6328 - loss: 0.7669 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 17/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6247 - loss: 0.7646 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 18/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6311 - loss: 0.7619 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 19/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6518 - loss: 0.7045 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 20/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6587 - loss: 0.7090 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 21/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6647 - loss: 0.7228 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 22/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6557 - loss: 0.6894 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 23/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6936 - loss: 0.6602 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 24/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6763 - loss: 0.6536 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 25/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7240 - loss: 0.6130 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 26/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6776 - loss: 0.6716 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 27/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6765 - loss: 0.6702 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 28/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6765 - loss: 0.6632 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 29/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6957 - loss: 0.6488 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n",
            "Epoch 30/30\n",
            "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6950 - loss: 0.6200 - val_accuracy: 0.0000e+00 - val_loss: 16.1181\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'optimized_cnn_model_in_memory.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KoEFUXCRD3bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oRVsCdsVD3Ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QFa6E2JoD3XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tBoX_xV2D3VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Juy64LzVD3SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EHhfdLSKD3Pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x6LhhvjUD3I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results in previous model are strange,\n",
        "i would expect validation to be at least 1/3 as a random choice\n"
      ],
      "metadata": {
        "id": "DYXDpKcadELb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wandb (if not already installed)\n",
        "!pip install wandb --quiet\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"cnn_spectrogram_classifier\", config={\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 16,\n",
        "    \"input_size\": (256, 256),\n",
        "    \"num_classes\": 3,\n",
        "    \"learning_rate\": 0.001\n",
        "})\n",
        "\n",
        "# --- Step 1: Define a Custom Data Generator for HDF5 ---\n",
        "class HDF5DataGenerator(Sequence):\n",
        "    def __init__(self, h5_file, batch_size, num_classes, input_size=(256, 256), train=True, split=0.9):\n",
        "        self.h5_file = h5py.File(h5_file, \"r\")  # Open file once\n",
        "        self.spectrograms = self.h5_file[\"spectrograms\"]\n",
        "        self.labels = self.h5_file[\"labels\"]\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Split into train and validation indices\n",
        "        total_samples = len(self.labels)\n",
        "        split_index = int(total_samples * split)\n",
        "\n",
        "        if train:\n",
        "            self.indices = np.arange(0, split_index)\n",
        "            np.random.shuffle(self.indices)  # Shuffle only training indices\n",
        "        else:\n",
        "            self.indices = np.arange(split_index, total_samples)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X = np.zeros((len(batch_indices), *self.input_size, 1), dtype=np.float32)\n",
        "        y = np.zeros((len(batch_indices), self.num_classes), dtype=np.float32)\n",
        "\n",
        "        for i, idx in enumerate(batch_indices):\n",
        "            X[i, :, :, 0] = self.spectrograms[idx]\n",
        "            label = self.labels[idx]\n",
        "            y[i, label] = 1.0  # One-hot encode the labels\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __del__(self):\n",
        "        self.h5_file.close()\n",
        "\n",
        "\n",
        "# --- Step 2: Paths and Generator Initialization ---\n",
        "h5_file = \"./chunks/chunk_0.h5\"\n",
        "batch_size = 16\n",
        "input_size = (256, 256)\n",
        "num_classes = 3\n",
        "\n",
        "train_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=True)\n",
        "val_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=False)\n",
        "\n",
        "# --- Step 3: Build the CNN Model ---\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same', input_shape=(*input_size, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, kernel_initializer='he_normal'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Callbacks: Reduce learning rate and Wandb\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "wandb_logger = WandbMetricsLogger()\n",
        "\n",
        "# --- Step 4: Train the Model ---\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[lr_scheduler, wandb_logger]\n",
        ")\n",
        "\n",
        "# --- Step 5: Save the Model ---\n",
        "model.save(\"cnn_classifier_saved_model\", save_format=\"tf\")  # TensorFlow format\n",
        "wandb.save(\"cnn_classifier_saved_model\")\n",
        "\n",
        "# --- Step 6: Plot Training History ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Model saved locally and logged to wandb.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FoLIZporF8_R",
        "outputId": "ef07a243-8e35-4c2f-b38d-eff237159c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfsirc\u001b[0m (\u001b[33mfsirc-czech-technical-university-in-prague\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241214_150407-swta16bn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/swta16bn' target=\"_blank\">icy-sun-3</a></strong> to <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/swta16bn' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/swta16bn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m4,194,432\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,432</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,293,443\u001b[0m (16.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,293,443</span> (16.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,292,707\u001b[0m (16.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,292,707</span> (16.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m736\u001b[0m (2.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> (2.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.4132 - loss: 1.3214 - val_accuracy: 0.0000e+00 - val_loss: 3.1093 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.4930 - loss: 1.0654 - val_accuracy: 0.0000e+00 - val_loss: 5.1827 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.5167 - loss: 0.9895 - val_accuracy: 0.0000e+00 - val_loss: 90.9099 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m162/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5797 - loss: 0.9255\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 2s/step - accuracy: 0.5799 - loss: 0.9252 - val_accuracy: 0.0000e+00 - val_loss: 447.8531 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m 36/169\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:49\u001b[0m 2s/step - accuracy: 0.6303 - loss: 0.8072"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b8578a0155e>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# --- Step 4: Train the Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wandb (if not already installed)\n",
        "!pip install wandb --quiet\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "# Enable mixed precision and XLA compilation\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"cnn_spectrogram_classifier\", config={\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 128,\n",
        "    \"input_size\": (256, 256),\n",
        "    \"num_classes\": 3,\n",
        "    \"learning_rate\": 0.0005\n",
        "})\n",
        "\n",
        "# --- Step 1: Define the HDF5 Data Generator ---\n",
        "class HDF5DataGenerator:\n",
        "    def __init__(self, h5_file, batch_size, num_classes, input_size=(256, 256), train=True, split=0.8):\n",
        "        self.h5_file_path = h5_file\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Open the HDF5 file to calculate indices\n",
        "        with h5py.File(h5_file, \"r\") as h5_file:\n",
        "            self.spectrograms = h5_file[\"spectrograms\"]\n",
        "            self.labels = h5_file[\"labels\"]\n",
        "            total_samples = len(self.labels)\n",
        "            split_index = int(total_samples * split)\n",
        "\n",
        "        self.train_indices = np.arange(0, split_index) if train else np.arange(split_index, total_samples)\n",
        "        if train:\n",
        "            np.random.shuffle(self.train_indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of batches per epoch.\n",
        "        \"\"\"\n",
        "        return len(self.train_indices) // self.batch_size\n",
        "\n",
        "    def __call__(self):\n",
        "        \"\"\"\n",
        "        Yields batches of data without re-opening the HDF5 file.\n",
        "        Efficiently handles chunked datasets.\n",
        "        \"\"\"\n",
        "        with h5py.File(self.h5_file_path, \"r\") as h5_file:\n",
        "            spectrograms = h5_file[\"spectrograms\"]\n",
        "            labels = h5_file[\"labels\"]\n",
        "            for i in range(0, len(self.train_indices), self.batch_size):\n",
        "                batch_indices = self.train_indices[i:i + self.batch_size]\n",
        "                X = np.zeros((len(batch_indices), *self.input_size, 1), dtype=np.float32)\n",
        "                y = np.zeros((len(batch_indices), self.num_classes), dtype=np.float32)\n",
        "\n",
        "                for j, idx in enumerate(batch_indices):\n",
        "                    # Resize spectrogram if necessary\n",
        "                    spectrogram = spectrograms[idx]\n",
        "                    if spectrogram.shape != self.input_size:\n",
        "                        spectrogram = tf.image.resize(spectrogram, self.input_size)\n",
        "                    X[j, :, :, 0] = spectrogram.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "                    y[j] = tf.keras.utils.to_categorical(labels[idx], self.num_classes)\n",
        "\n",
        "                yield X, y\n",
        "\n",
        "# --- Step 2: Wrap Data Generators into tf.data.Dataset ---\n",
        "def get_tf_dataset(generator, batch_size):\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(batch_size, *input_size, 1), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(batch_size, num_classes), dtype=tf.float32),\n",
        "        )\n",
        "    )\n",
        "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Initialize datasets\n",
        "h5_file = \"./chunks/chunk_0.h5\"  # Path to your HDF5 file (adjust if needed)\n",
        "batch_size = 128\n",
        "input_size = (256, 256)\n",
        "num_classes = 3\n",
        "\n",
        "train_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=True)\n",
        "val_generator = HDF5DataGenerator(h5_file, batch_size, num_classes, input_size, train=False)\n",
        "\n",
        "train_dataset = get_tf_dataset(train_generator, batch_size)\n",
        "val_dataset = get_tf_dataset(val_generator, batch_size)\n",
        "\n",
        "# --- Step 3: Build the CNN Model ---\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same', input_shape=(256, 256, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),  # Efficient pooling instead of Flatten\n",
        "    layers.Dense(128, kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Callbacks: Reduce learning rate, early stopping, and Wandb\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "wandb_logger = WandbMetricsLogger()\n",
        "\n",
        "# --- Step 4: Train the Model ---\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[lr_scheduler, early_stopping, wandb_logger]\n",
        ")\n",
        "\n",
        "# --- Step 5: Save the Model ---\n",
        "model.save(\"cnn_classifier_saved_model\", save_format=\"tf\")\n",
        "wandb.save(\"cnn_classifier_saved_model\")\n",
        "\n",
        "# --- Step 6: Plot Training History ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Model saved locally and logged to wandb.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a6a6ed9d2d1d4bf4944cb43d2ed3907d",
            "89fe9805f4cd46beb7d043536d61c03e",
            "0bb6e9ba95474dfdbf925750be43242c",
            "854cd55721f749d79d864349fa9b269c",
            "8782a86e9b9541ceb6ffc0bf5a9de88d",
            "4a843cfaa42e4fa7b662230ab9458b62",
            "ac099204eaa8473ba2eb9759f6d748d6",
            "4e6ce07183aa4d548551fdb1b5ea790c"
          ]
        },
        "id": "JD4mTUIMrZrt",
        "outputId": "9ddbce54-fe02-4a72-9475-f75db0cfe07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:onp2hx3v) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6a6ed9d2d1d4bf4944cb43d2ed3907d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">woven-cherry-12</strong> at: <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/onp2hx3v' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/onp2hx3v</a><br/> View project at: <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241214_161511-onp2hx3v/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:onp2hx3v). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241214_161820-gea3r8fu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/gea3r8fu' target=\"_blank\">whole-serenity-13</a></strong> to <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/gea3r8fu' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/gea3r8fu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_40 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_32 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_41               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_41 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_33 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_42 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_34 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_43 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_35 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_44               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_44 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_41               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_44               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,523\u001b[0m (451.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,523</span> (451.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,787\u001b[0m (448.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,787</span> (448.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m736\u001b[0m (2.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> (2.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_32\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 128, 256, 256)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 128, 256, 256, 1), dtype=float32)\n  • training=True\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b9919677afab>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# --- Step 4: Train the Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"conv2d_32\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 128, 256, 256)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 128, 256, 256, 1), dtype=float32)\n  • training=True\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3oaIGBjiCksY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aL0fUXIC7t-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def display_h5_params(h5_file_path):\n",
        "    # Open the HDF5 file\n",
        "    with h5py.File(h5_file_path, 'r') as h5_file:\n",
        "        # Iterate over all datasets in the HDF5 file\n",
        "        for dataset_name in h5_file:\n",
        "            dataset = h5_file[dataset_name]\n",
        "            print(f\"Dataset name: {dataset_name}\")\n",
        "            print(f\"Shape: {dataset.shape}\")\n",
        "            print(f\"Datatype: {dataset.dtype}\")\n",
        "            print(f\"Number of elements: {dataset.size}\")\n",
        "            print(f\"Chunks: {dataset.chunks}\")\n",
        "            print(f\"Compression: {dataset.compression}\")\n",
        "            print(f\"Compression level: {dataset.compression_opts}\")\n",
        "            print(f\"Attributes: {dict(dataset.attrs)}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "# Example usage\n",
        "h5_file_path = \"./chunks/chunk_0.h5\"  # Path to your HDF5 file\n",
        "display_h5_params(h5_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbihFpya7wBD",
        "outputId": "b2108189-fcc3-48ab-d233-a2e7bba49e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset name: labels\n",
            "Shape: (3000,)\n",
            "Datatype: int32\n",
            "Number of elements: 3000\n",
            "Chunks: (3000,)\n",
            "Compression: gzip\n",
            "Compression level: 4\n",
            "Attributes: {}\n",
            "--------------------------------------------------\n",
            "Dataset name: spectrograms\n",
            "Shape: (3000, 256, 256)\n",
            "Datatype: float32\n",
            "Number of elements: 196608000\n",
            "Chunks: (94, 16, 16)\n",
            "Compression: gzip\n",
            "Compression level: 4\n",
            "Attributes: {}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wandb (if not already installed)\n",
        "!pip install wandb --quiet\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "# Enable mixed precision and XLA compilation\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"cnn_spectrogram_classifier\", config={\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 128,\n",
        "    \"input_size\": (256, 256),\n",
        "    \"num_classes\": 3,\n",
        "    \"learning_rate\": 0.0005\n",
        "})\n",
        "\n",
        "# --- Step 1: Load HDF5 Dataset into RAM ---\n",
        "def load_h5_to_memory(h5_file_path, split=0.8):\n",
        "    \"\"\"\n",
        "    Loads the HDF5 file into memory as NumPy arrays for both training and validation sets.\n",
        "    \"\"\"\n",
        "    with h5py.File(h5_file_path, \"r\") as h5_file:\n",
        "        spectrograms = np.array(h5_file[\"spectrograms\"], dtype=np.float32) / 255.0  # Normalize [0, 1]\n",
        "        labels = np.array(h5_file[\"labels\"], dtype=np.int32)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    num_classes = len(np.unique(labels))\n",
        "    labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    split_index = int(len(labels) * split)\n",
        "    X_train, X_val = spectrograms[:split_index], spectrograms[split_index:]\n",
        "    y_train, y_val = labels[:split_index], labels[split_index:]\n",
        "\n",
        "    # Reshape to include channel dimension\n",
        "    X_train = X_train[..., np.newaxis]  # Shape: (samples, 256, 256, 1)\n",
        "    X_val = X_val[..., np.newaxis]\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val)\n",
        "\n",
        "# Load dataset into RAM\n",
        "h5_file_path = \"./chunks/chunk_0.h5\"\n",
        "(X_train, y_train), (X_val, y_val) = load_h5_to_memory(h5_file_path)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "# --- Step 2: Build the CNN Model ---\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same', input_shape=(256, 256, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),  # Efficient pooling instead of Flatten\n",
        "    layers.Dense(128, kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # num_classes = 3\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0005, clipnorm=1.0)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Callbacks: Reduce learning rate, early stopping, and Wandb\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "wandb_logger = WandbMetricsLogger()\n",
        "\n",
        "# --- Step 3: Train the Model ---\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[lr_scheduler, early_stopping, wandb_logger]\n",
        ")\n",
        "\n",
        "# --- Step 4: Save the Model ---\n",
        "model.save(\"cnn_classifier_saved_model\", save_format=\"tf\")\n",
        "wandb.save(\"cnn_classifier_saved_model\")\n",
        "\n",
        "# --- Step 5: Plot Training History ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Model saved locally and logged to wandb.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "856579a7a209474e9b9f26e25b21e1fd",
            "a144fa2bef02472b91287c52c021f0a2",
            "333da846c01b49ac89226cebf72fb218",
            "e82f8403d40e4103acd8f06e2b77e532",
            "3f6ee70a9da04cad9020e0db4ce5ed94",
            "5a8b47b43f1d43269f141365eb50c5ff",
            "f880959c02cb4d24976781232c9ea44d",
            "d26434fd89d846928110896d1c607ef6"
          ]
        },
        "id": "DYBp0Ds487sJ",
        "outputId": "b59aa226-4bef-4f8c-c37b-90b849a83c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:969o7if2) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "856579a7a209474e9b9f26e25b21e1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polar-plasma-15</strong> at: <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/969o7if2' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/969o7if2</a><br/> View project at: <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241214_162129-969o7if2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:969o7if2). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241214_163623-tm85qlfj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/tm85qlfj' target=\"_blank\">bright-yogurt-16</a></strong> to <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/tm85qlfj' target=\"_blank\">https://wandb.ai/fsirc-czech-technical-university-in-prague/cnn_spectrogram_classifier/runs/tm85qlfj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (2400, 256, 256, 1), (2400, 3)\n",
            "Validation set shape: (600, 256, 256, 1), (600, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_55               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_55 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_44 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_56               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_56 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_45 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_57               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_57 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_46 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_58               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_58 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_47 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_59               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_59 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_55               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_56               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_57               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_58               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_59               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,523\u001b[0m (451.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,523</span> (451.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,787\u001b[0m (448.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,787</span> (448.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m736\u001b[0m (2.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> (2.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 851ms/step - accuracy: 0.3881 - loss: 1.5146 - val_accuracy: 0.0000e+00 - val_loss: 1.4110 - learning_rate: 5.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4236 - loss: 1.3355 - val_accuracy: 0.0000e+00 - val_loss: 1.7033 - learning_rate: 5.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4360 - loss: 1.2813 - val_accuracy: 0.0000e+00 - val_loss: 2.1873 - learning_rate: 5.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4140 - loss: 1.2565\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4151 - loss: 1.2561 - val_accuracy: 0.0000e+00 - val_loss: 2.8138 - learning_rate: 5.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4510 - loss: 1.2344 - val_accuracy: 0.0000e+00 - val_loss: 3.5582 - learning_rate: 2.5000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4286 - loss: 1.2387 - val_accuracy: 0.0000e+00 - val_loss: 4.3101 - learning_rate: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ec9752b9ed8b>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# --- Step 4: Save the Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cnn_classifier_saved_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cnn_classifier_saved_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             )\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0;34m\"The `save_format` argument is deprecated in Keras 3. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;34m\"Please remove this argument and pass a file path with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `save_format` argument is deprecated in Keras 3. Please remove this argument and pass a file path with either `.keras` or `.h5` extension.Received: save_format=tf"
          ]
        }
      ]
    }
  ]
}